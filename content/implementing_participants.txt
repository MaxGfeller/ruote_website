---
title: implementing participants
---

h2. implementing participants

Participant receive workitems, do something about/to them. Then, if necessary, they reply to ruote with the [updated] workitem.

In its simplest form a participant implementation will take the form of a "block participant":/part/block_participant.html.

<pre class="brush: ruby">
engine.register_participant :flush_garbage do |workitem|
  GarbageCan.find(workitem.fields['garbage_can_id']).flush
end
</pre>

In fact, this is equivalent to the following participant implementation (and registration) :

<pre class="brush: ruby">
class Flusher
  include Ruote::LocalParticipant

  def consume(workitem)
    GarbageCan.find(workitem.fields['garbage_can_id']).flush
    reply_to_engine(workitem)
  end

  def cancel(fei, flavour)
    # nothing to do
  end

  #def on_reply(workitem)
  #end
end

engine.register_participant :flush_garbage, Flusher
</pre>

Yes, you are right, the block participant's block is reproduced in the consume method of the participant implementation, but a reply_to_engine(workitem) is added.

"#consume":#consume isn't the only method involved in a participant, there is also "#cancel":#cancel. Cancel is called when a process instance or a segment of it gets cancelled and the participant holds a workitem for the segment. The workitem has to be somehow cancelled / removed / rolled back.

Two optional methods also exist : "#accept?":#accept and "#on_reply":#on_reply. A participant with an accept? method is free to discard incoming workitems that it doesn't like. A participant with an on_reply method is usually some kind of proxy for a real (remote) participant; the on_reply method, when present, is called when the answer (workitem) comes back from the real participant.

By default, when a process instance execution reaches a participant expression, it runs the #consume method of the participant in a dedicated Ruby thread. if the "#do_not_thread":#do_not_thread method returns false, no extra thread is created, the consume call is done immediately (ie, it blocks the worker).

From *ruote 2.3.0* on, our flusher example can be re-written as

<pre class="brush: ruby">
class Flusher
  include Ruote::LocalParticipant

  def on_workitem
    GarbageCan.find(workitem.fields['garbage_can_id']).flush
    reply
  end

  def on_cancel
    # nothing to do
  end

  #def on_reply
  #end
end

engine.register_participant :flush_garbage, Flusher
</pre>

where the 'consume' got renamed to 'on_workitem' and 'cancel' to 'on_cancel'. This to emphasize the reactive nature of participants.

Note that the workitem, fei and flavour are now implicit, you can declare them as args or not.


h3(#local_participant). Ruote::LocalParticipant

Most of the time, you'll want your participant to include the Ruote::LocalParticipant mixin.

It's named 'local' because it supposed to have access to the ruote storage.

***

Methods to implement or override when implementing a participant and some helpers granted by Ruote::LocalParticipant.

h3. methods

* "#consume":#consume ("#on_workitem":#on_workitem)
* "#cancel":#cancel ("#on_cancel":#on_cancel)
* "#accept?":#accept
* "#on_apply":#on_apply
* "#on_reply":#on_reply
* "#do_not_thread":#do_not_thread ("#dont_thread?":#dont_thread)

* "#re_dispatch":#re_dispatch
* "#unschedule_re_dispatch":#unschedule_re_dispatch

* "#rtimeout":#rtimeout

h3. helpers

* "reply_to_engine":#reply_to_engine ("reply":#reply)
* "fexp":#fexp
* "workitem":#workitem
* "applied_workitem":#applied_workitem
* "participant_name":#participant_name
* "lookup_variable":#lookup_variable
* "put and get":#stash


***


h3(#consume). #consume #on_workitem <a name="on_workitem"></a>

When a participant is handed a workitem, this method is called with the workitem as the argument.

<pre class="brush: ruby">
# computing the total for a invoice being passed in the workitem.
#
class TotalParticipant
  include Ruote::LocalParticipant

  def consume(workitem)
    workitem.fields['total'] =
      workitem.fields['items'].inject(0.0) { |t, item|
        t + item['count'] * PricingService.lookup(item['id'])
      }
    reply_to_engine(workitem)
  end
end
</pre>

Note the call to #reply_to_engine with the workitem as argument when the work is done. Without this call (sooner or later), the process doesn't resume after this participant.

From ruote 2.3.0 on, the above participant can be written as :

<pre class="brush: ruby">
# computing the total for a invoice being passed in the workitem.
#
class TotalParticipant
  include Ruote::LocalParticipant

  def on_workitem
    workitem.fields['total'] =
      workitem.fields['items'].inject(0.0) { |t, item|
        t + item['count'] * PricingService.lookup(item['id'])
      }
    reply
  end
end
</pre>


h3(#cancel). #cancel #on_cancel <a name="on_cancel"></a>

If you don't immediately (and very quickly) reply to the engine in your consume method, you'd better have a #cancel implementation for your class.

<pre class="brush: ruby">
require 'fileutils'
require 'yaml'

# A plain "worklist" implementations, workitems are placed in files under
# worklist/
#
# We assume the rest of the application reads those yaml files and
# calls PlainWorklist.reply(workitem_h) when done with a workitem.
#
class PlainWorklist
  include Ruote::LocalParticipant

  # Called by ruote when there's work for our participant
  #
  def consume(workitem)
    h = workitem.to_h
    h['fei'] = workitem.fei.sid
    File.open("worklist/workitem_#{workitem.fei.sid}.yaml", wb) do |f|
      f.puts(h.to_yaml)
    end
    # no reply_to_engine(workitem)
  end

  # When ruote has to cancel a process instance with an active workitem
  # for this participant, this method is called.
  #
  def cancel(fei, flavour)
    FileUtils.rm("worklist/workitem_#{fei.sid}.yaml")
  end

  # A method called by external systems when they're done with a workitem
  # hash, they hand it back to the engine via this method.
  #
  def self.reply(workitem_h)
    FileUtils.rm("worklist/workitem_#{workitem_h['fei']}.yaml")
    reply_to_engine(workitem)
  end
end
</pre>

Our consume method doesn't reply to the engine, at all. The reply occurs later, in the #reply class method. If a cancel order comes, the workitem stored on disk has to be removed.

From ruote 2.3.0 on, you can write :

<pre class="brush: ruby">
require 'fileutils'
require 'yaml'

# A plain "worklist" implementations, workitems are placed in files under
# worklist/
#
# We assume the rest of the application reads those yaml files and
# calls PlainWorklist.reply(workitem_h) when done with a workitem.
#
class PlainWorklist
  include Ruote::LocalParticipant

  # Called by ruote when there's work for our participant
  #
  def on_workitem
    h = workitem.to_h
    h['fei'] = workitem.fei.sid
    File.open("worklist/workitem_#{workitem.fei.sid}.yaml", wb) do |f|
      f.puts(h.to_yaml)
    end
    # no reply_to_engine
  end

  # When ruote has to cancel a process instance with an active workitem
  # for this participant, this method is called.
  #
  def on_cancel
    FileUtils.rm("worklist/workitem_#{fei.sid}.yaml")
  end

  # A method called by external systems when they're done with a workitem
  # hash, they hand it back to the engine via this method.
  #
  def self.reply(workitem_h)
    FileUtils.rm("worklist/workitem_#{workitem_h['fei']}.yaml")
    receive(workitem)
  end
end
</pre>

From ruote 2.3.0 on, when #on_cancel returns false, no reply will be emitted towards ruote. It can be useful in scenarii where the #on_workitem itself deals with cancel messages (and it has some way to know about them...).

h4(#flavour). cancel flavour

This parameter is usually set to 'cancel'. When a process is "killed instead of cancelled":/process_administration.html#killing, the flavour is set to "kill". Usually this parameter is simply ignored, but who knows, perhaps a different behaviour might be necessary in some context ?


h3(#accept). #accept?

Given a list of participant

<pre class="brush: ruby">
engine.register_participant 'al.+', FirstParticipantImplementation
engine.register_participant 'al.+', SecondParticipantImplementation
</pre>

the first participant whose regex matches the participant name is used. If that first participant has a method #accept?(workitem), it's called and if it replies with false, the next participant in the participant list is tried.

<pre class="brush: ruby">
class FirstParticipantImplementation
  include Ruote::LocalParticipant

  # Do something...
  #
  def consume(workitem)
    workitem.fields['message'] = 'kilroy was here'
    reply_to_engine(workitem)
  end

  # This participant will not accept workitems for non military contexts.
  # The next matching participant in the participant list will be consulted.
  #
  def accept?(workitem)
    workitem.fields['context'] == 'military'
  end
end
</pre>

From ruote 2.3.0 on, the accept? method can be rewritten as :

<pre class="brush: ruby">
  def accept?
    workitem.fields['context'] == 'military'
  end
</pre>


h3(#on_apply). #on_apply

(since ruote 2.3.0)

Equivalent to "on_reply":#on_reply, but triggers before the workitem is dispatched to the participant. It gives participant implementers an opportunity to perform some operations before the dispatch. The typical example is adding some information to the workitem before it's passed on.

Note, that like for 'on_reply':#on_reply, on_apply is executed in the worker thread (whereas dispatch is performed, by default, in a new thread).


h3(#on_reply). #on_reply

Roughly, there are two categories of participants, those who receive a workitem and reply immediately and those who take some time before replying.

In this second category, one can find participants that emit workitem to a remote participant. The workitem comes back via a listener usually.

Participants that provide a #on_reply(workitem) implementation are given a opportunity to tweak the workitem once it comes back.

Here is an example where an hypothetical WorkQueue is placed between the ruote system and the remote participant bound under the name "remote". The receiver pops messages and feeds the back to the engine. When workitems come back, the worker will hand it to the on_reply method of the participant.

<pre class="brush: ruby">
class MyRemoteParticipant
  #include Ruote::LocalParticipant

  def consume(workitem)
    WorkQueue.push(workitem_to_msg(workitem))
  end

  def on_reply(workitem)
    workitem.fields['msg'] = "back at #{Time.now.to_s}"
  end

  protected

  def workitem_to_msg(workitem)
    # ...
  end
end

class Receiver < Ruote::Receiver

  def initialize(engine)
    super
    Thread.new { listen }
  end

  protected

  def listen

    loop { reply_to_engine(workitem_from_msg(WorkQueue.pop)) }
  end

  def workitem_from_msg(msg)
    # ...
  end
end

engine = Ruote::Engine.new(Ruote::Worker.new(Ruote::HashStorage.new))

engine.register_participant :remote, MyRemoteParticipant

receiver = Receiver.new(engine)

# ...
</pre>

From ruote 2.3.0, the on_reply method can be rewritten as :

<pre class="brush: ruby">
  def on_reply
    workitem.fields['msg'] = "back at #{Time.now.to_s}"
  end
</pre>


h3(#do_not_thread). #do_not_thread #dont_thread? <a name="dont_thread"> </a>

By default, when dispatching a workitem to a participant, a ruote worker will call the participant's consume method in a new thread. The idea is to move the [potentially] bulk work of dispatching outside of the worker loop very quickly.

This is not always appropriate. The participant can tell the worker not to spawn a new thread by implementing a do_not_thread method and letting it reply with true when it's called.

<pre class="brush: ruby">
class MyParticipant
  include Ruote::LocalParticipant

  # Do something...
  #
  def consume(workitem)
    workitem.fields['message'] = 'kilroy was here'
    reply_to_engine(workitem)
  end

  # The consume method does such a trivial thing that it's not worth spawning
  # a thread.
  #
  def do_not_thread
    true
  end
end
</pre>

It's OK to have a do_not_thread method that accepts the workitem as argument :

<pre class="brush: ruby">
  def do_not_thread(workitem)
    workitem.fields['colour'] == 'blue'
  end
</pre>

If you want to influence more radically threading while dispatching, overriding the dispatch_pool service is probably the best solution.

<pre class="brush: ruby">
#
# This implementation never dispatches in a new thread...
#
class MyDispatchPool < Ruote::DispatchPool

  def dispatch(msg)

    participant = @context.plist.lookup(
      msg['participant'] || msg['participant_name'], msg['workitem'])

    do_dispatch(participant, msg)
  end
end

# ...

opts = {
  's_dispatch_pool' => [ 'path/to/my_dispatch_pool', 'MyDispatchPool' ]
}

engine = Ruote::Engine.new(Ruote::Worker.new(Ruote::HashStorage.new(opts)))
</pre>

or something like that...

From ruote 2.3.0 on, you can use the dont_thread? method instead, and the workitem is implicit (like from #on_workitem and #on_reply). So this is OK :

<pre class="brush: ruby">
  def dont_thread?
    workitem.fields['colour'] == 'blue'
  end
</pre>


h3(#re_dispatch). #re_dispatch

Use this method to re_dispatch the workitem.

It takes two options :in and :at for "later re_dispatch". Without one of those options, the method is a "reject".

Here is an example where re_dispatch is used to implement a retry tactic.

<pre class="brush: ruby">
class RetryParticipant
  include Ruote::LocalParticipant

  def initialize(opts)
    @opts = opts
  end

  def consume(workitem)
    begin
      do_the_job
      reply(workitem)
    rescue
      re_dispatch(workitem, :in => @opts['delay'] || '1s')
    end
  end

  def cancel(fei, flavour)
    unschedule_re_dispatch(fei)
  end
end
</pre>

re_dispatch/reject makes sense too in a multi worker context where a participant on a given host wants to reject a task and let another worker (on another host) do the work. Maybe the "accept?":#accept method is better for those cases, though.

From ruote 2.3.0, our above example can be simplified to :

<pre class="brush: ruby">
class RetryParticipant
  include Ruote::LocalParticipant

  def initialize(opts)
    @opts = opts
  end

  def on_workitem
    begin
      do_the_job
      reply
    rescue
      re_dispatch(:in => @opts['delay'] || '1s')
    end
  end

  def on_cancel
    unschedule_re_dispatch
  end
end
</pre>


h3(#unschedule_re_dispatch). #unschedule_re_dispatch

Look at the example in the "previous section":#re_dispatch to see unschedule_re_dispatch in action.


h3(#rtimeout). #rtimeout

Usually, timeouts are given for an expression in the process definition.

<pre class="brush: ruby">
participant 'alice', :timeout => '2d'
</pre>

where alice as two days to complete her task (send back the workitem).

But it's OK for participant classes registered in the engine to provide
their own timeout value. The participant instance simply has to reply to
the #rtimeout method and provide a meaningful timeout value (like a
number of seconds, or a string like "2d" or "1M2w". For example :

<pre class="brush: ruby">
class MyParticipant
  # ...
  def rtimeout(workitem)
    workitem.fields['category'] == 'shoes' ? '2w' : '1w'
  end
  # ...
end
</pre>

From ruote 2.3.0 on, the workitem is implicit :

<pre class="brush: ruby">
class MyParticipant
  # ...
  def rtimeout
    workitem.fields['category'] == 'shoes' ? '2w' : '1w'
  end
  # ...
end
</pre>

Note however, that the process definition timeout (if any) will take
precedence over the participant specified one.


***


h3(#reply_to_engine). reply_to_engine reply <a name="reply"> </a>

Often used at the engine of a consume implementation.

<pre class="brush: ruby">
class Total
  include Ruote::LocalParticipant

  def consume(workitem)
    workitem.fields['total'] =
      workitem.fields['items'].inject(0) { |t, (i, c)|
        item = Item.find(i)
        t = t + c * item.price
      }
    reply_to_engine(workitem)
  end
end

engine.register 'total', Total
</pre>

If you scroll a bit, you'll find "an example":#applied_workitem where this method is called outside of the consume method.

#reply_to_engine(workitem) can be shortened to #reply(workitem).

From ruote 2.3.0 on, you can even drop the 'workitem'.

<pre class="brush: ruby">
class Total
  include Ruote::LocalParticipant

  def on_workitem
    workitem.fields['total'] =
      workitem.fields['items'].inject(0) { |t, (i, c)|
        item = Item.find(i)
        t = t + c * item.price
      }
    reply
  end
end

engine.register 'total', Total
</pre>


h3(#fexp). fexp

Via this method, the participant implementation has access to its [participant] expression.

<pre class="brush: ruby">
class PickCustomer
  include Ruote::LocalParticipant

  def consume(workitem)
    customers = fexp(workitem).lookup_variable('customers')
    workitem.fields['customer'] = customers[rand(customers.length)]
    reply_to_engine(workitem)
  end
end

engine.register 'pick_customer', PickCustomer
</pre>

From ruote 2.3.0 on, you have to drop the fexp argument can be dropped :

<pre class="brush: ruby">
class PickCustomer
  include Ruote::LocalParticipant

  def on_workitem
    customers = fexp.lookup_variable('customers')
    workitem.fields['customer'] = customers[rand(customers.length)]
    reply
  end
end

engine.register 'pick_customer', PickCustomer
</pre>


h3(#workitem). workitem

Whereas applied_workitem returns the workitem as was applied (to the participant expression), workitem returns the workitem as was dispatched to this participant [implementation].

The main difference is that a workitem as dispatched contains the 'params' field corresponding to the attributes specified in the process definition.


h3(#applied_workitem). applied_workitem

Especially when a participant is meant as a task list, workitems may get modified and not immediately replied (proceeded) to the engine.

It could be necessary to look at a copy of the workitem as it was when it reached the participant [expression].

<pre class="brush: ruby">
class TaskList
  include Ruote::LocalParticipant

  def initialize(opts)
    @tasks = connect_to_some_db(opts)
  end

  def consume(workitem)
    @tasks[workitem.fei] = workitem
  end

  def cancel(fei, flavour)
    @tasks.delete(fei)
  end

  def by_user(username)
    @tasks.by(:user => username)
  end

  def update(workitem)
    @tasks[workitem.fei] = workitem
  end

  def original(workitem)
    applied_workitem(workitem)
  end

  def self.reply(workitem)
    if @tasks.delete[workitem.fei]
      reply_to_engine(workitem)
    end
  end
end

# ...

engine.register 'user_.+', TaskList

# ...

tasklist = engine.participant('user_x')
  # returns an instance of our participant, 'user_x' will do since
  # it's registered for any participant starting with 'user_'

workitem = tasklist.by_user('user_fred').first

if workitem.fields != tasklist.original(workitem).fields
  puts "fred's workitem got modified"
end

tasklist.reply(workitem)
</pre>

Note the use of Engine#participant(name) to fetch an instance of a participant via the engine.


h3(#participant_name). participant_name

Since ruote 2.3.0, it's ok to shorten

<pre class="brush: ruby">
def consume(workitem)
  (workitem.fields['supervisors'] ||= []) << workitem.participant_name
  reply_to_engine(workitem)
end
</pre>

to

<pre class="brush: ruby">
def on_workitem
  (workitem.fields['supervisors'] ||= []) << participant_name
  reply
end
</pre>

(the simplification to notice here is the one from "workitem.participant_name" to "participant_name", well it's not the only simplification...)


h3(#lookup_variable). lookup_variable

Available since ruote 2.3.0.

<pre class="brush: ruby">
def on_workitem
  workitem.fields['my_var'] = lookup_variable('my_var')
  workitem.fields['my_other_var'] = fexp.lookup_variable('my_other_var')
  reply
end
</pre>


h3(#stash). put and get

Sometimes participant implementations need to stash data somewhere, but they can't do it in the workitem itself (visibility issues). There are the _put_ and _get_ methods available.

You'll find an example at the end of this "discussion thread":http://groups.google.com/group/openwferu-users/browse_thread/thread/2e6a95708c10847b.

